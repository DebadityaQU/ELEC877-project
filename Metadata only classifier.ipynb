{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861bc8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41d87b9",
   "metadata": {},
   "source": [
    "Column 1: the ID of the statement ([ID].json).\n",
    "\n",
    "Column 2: the label.\n",
    "\n",
    "Column 3: the statement.\n",
    "\n",
    "Column 4: the subject(s).\n",
    "\n",
    "Column 5: the speaker.\n",
    "\n",
    "Column 6: the speaker's job title.\n",
    "\n",
    "Column 7: the state info.\n",
    "\n",
    "Column 8: the party affiliation.\n",
    "\n",
    "Column 9-13: the total credit history count, including the current statement.\n",
    "\n",
    "9: barely true counts.\n",
    "\n",
    "10: false counts.\n",
    "\n",
    "11: half true counts.\n",
    "\n",
    "12: mostly true counts.\n",
    "\n",
    "13: pants on fire counts.\n",
    "\n",
    "Column 14: the context (venue / location of the speech or statement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d950de",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"ID\",\n",
    "    \"label\",\n",
    "    \"statement\",\n",
    "    \"subjects\",\n",
    "    \"speaker\",\n",
    "    \"speaker_job\",\n",
    "    \"state_info\",\n",
    "    \"party_affiliation\",\n",
    "    \"barely_true_counts\",\n",
    "    \"false_counts\",\n",
    "    \"half_true_counts\",\n",
    "    \"mostly_true_counts\",\n",
    "    \"pants_on_fire_counts\",\n",
    "    \"context\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9c5c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb6b1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.tsv\", encoding=\"utf-8\", delimiter=\"\\t\", header=None, names=columns)\n",
    "valid_df = pd.read_csv(\"valid.tsv\", encoding=\"utf-8\", delimiter=\"\\t\", header=None, names=columns)\n",
    "test_df = pd.read_csv(\"test.tsv\", encoding=\"utf-8\", delimiter=\"\\t\", header=None, names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefd423b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"statement\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcb999b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5a7fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_metadata(x):\n",
    "    \n",
    "    subject = x[\"subjects\"]\n",
    "    speaker = x[\"speaker\"]\n",
    "    job = x[\"speaker_job\"]\n",
    "    state_info = x[\"state_info\"]\n",
    "    party = x[\"party_affiliation\"]\n",
    "    context = x[\"context\"]\n",
    "    \n",
    "    metadata = f\"\"\"SUBJECT: {subject}\n",
    "        SPEAKER: {speaker}\n",
    "        JOB: {job}\n",
    "        STATE INFO: {state_info}\n",
    "        PARTY: {party}\n",
    "        CONTEXT: {context}\n",
    "        \"\"\"\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea8d696",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750886ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"metadata\"] = train_df.apply(lambda x: join_metadata(x), axis=1)\n",
    "test_df[\"metadata\"] = test_df.apply(lambda x: join_metadata(x), axis=1)\n",
    "valid_df[\"metadata\"] = valid_df.apply(lambda x: join_metadata(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcddad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"content\"] = train_df[\"statement\"].copy()\n",
    "test_df[\"content\"] = test_df[\"statement\"].copy()\n",
    "valid_df[\"content\"] = valid_df[\"statement\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d5c1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[[\"content\", \"metadata\", \"label\"]]\n",
    "valid_df = valid_df[[\"content\", \"metadata\", \"label\"]]\n",
    "test_df = test_df[[\"content\", \"metadata\", \"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37f4857",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde8d81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {label: i for i, label in enumerate(train_df['label'].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7ea84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"label\"] = train_df[\"label\"].map(label_map)\n",
    "valid_df[\"label\"] = valid_df[\"label\"].map(label_map)\n",
    "test_df[\"label\"] = test_df[\"label\"].map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e991a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3560ec42",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d25bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1c15c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, pipeline\n",
    "\n",
    "class FakeNewsDataset(Dataset):\n",
    "    def __init__(self, dataframe, max_length=512):\n",
    "        self.data = dataframe\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        content = self.data['content'][idx]\n",
    "        metadata = self.data['metadata'][idx]\n",
    "        label = self.data['label'][idx]\n",
    "\n",
    "        # Lowercase the text\n",
    "        content = content.lower()\n",
    "        metadata = metadata.lower()\n",
    "        \n",
    "        # Remove special characters\n",
    "        content = re.sub(r'[^\\w\\s]','',content)\n",
    "        metadata = re.sub(r'[^\\w\\s]','',metadata)\n",
    "        \n",
    "        # Tokenize content\n",
    "        content_inputs = self.tokenizer.encode_plus(\n",
    "            content,\n",
    "            None,\n",
    "            pad_to_max_length=True,\n",
    "            add_special_tokens=True,\n",
    "            return_attention_mask=True,\n",
    "            max_length=self.max_length,\n",
    "        )\n",
    "        content_ids = content_inputs[\"input_ids\"]\n",
    "        content_token_type_ids = content_inputs[\"token_type_ids\"]\n",
    "        content_mask = content_inputs[\"attention_mask\"]\n",
    "\n",
    "        content_tokens = {\n",
    "            'ids': torch.tensor(content_ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(content_mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(content_token_type_ids, dtype=torch.long),\n",
    "        }\n",
    "        \n",
    "        # Tokenize metadata\n",
    "        metadata_inputs = self.tokenizer.encode_plus(\n",
    "            metadata,\n",
    "            None,\n",
    "            pad_to_max_length=True,\n",
    "            add_special_tokens=True,\n",
    "            return_attention_mask=True,\n",
    "            max_length=self.max_length,\n",
    "        )\n",
    "        metadata_ids = metadata_inputs[\"input_ids\"]\n",
    "        metadata_token_type_ids = metadata_inputs[\"token_type_ids\"]\n",
    "        metadata_mask = metadata_inputs[\"attention_mask\"]\n",
    "\n",
    "        metadata_tokens = {\n",
    "            'ids': torch.tensor(metadata_ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(metadata_mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(metadata_token_type_ids, dtype=torch.long),\n",
    "        }\n",
    "        \n",
    "        # Convert the labels to integers\n",
    "        label = self.data['label'][idx]\n",
    "\n",
    "        return content_tokens, metadata_tokens, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6853fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FakeNewsDataset(train_df)\n",
    "valid_dataset = FakeNewsDataset(valid_df)\n",
    "test_dataset = FakeNewsDataset(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf011eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "        train_dataset, batch_size=24,\n",
    "        shuffle=True\n",
    ")\n",
    "\n",
    "valid_dataloader = DataLoader(\n",
    "        valid_dataset, batch_size=24,\n",
    "        shuffle=True\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "        test_dataset, batch_size=24,\n",
    "        shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525c5122",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_features, metadata_features, labels = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53adc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_dim=768, num_ff_layers=6, ff_dim=3072, dropout_prob=0.2):\n",
    "        super(Classifier, self).__init__()\n",
    "        \n",
    "        self.bert_model = transformers.BertModel.from_pretrained(\"bert-based-uncased\")\n",
    "        \n",
    "        # Define the Query, Key, and Value Linear layers\n",
    "        self.query_layer = nn.Linear(input_dim, input_dim)\n",
    "        self.key_layer = nn.Linear(input_dim, input_dim)\n",
    "        self.value_layer = nn.Linear(input_dim, input_dim)\n",
    "\n",
    "        # Define the FeedForward layers\n",
    "        self.ff_layers = nn.ModuleList()\n",
    "        for i in range(num_ff_layers):\n",
    "            self.ff_layers.append(nn.Sequential(\n",
    "                nn.Linear(input_dim, ff_dim),\n",
    "                nn.GELU(),\n",
    "                nn.Dropout(dropout_prob),\n",
    "                nn.Linear(ff_dim, input_dim),\n",
    "                nn.GELU(),\n",
    "                nn.Dropout(dropout_prob)\n",
    "            ))\n",
    "\n",
    "        # Define the classifier layer\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(input_dim, len(label_map.keys())),\n",
    "        )\n",
    "\n",
    "        # Define the LayerNormalization layer\n",
    "        self.layer_norm = nn.LayerNorm(input_dim)\n",
    "\n",
    "    def forward(self, \n",
    "                metadata_ids,\n",
    "                metadata_mask,\n",
    "                metadata_token_type_ids,\n",
    "               ):\n",
    "        \n",
    "        _, metadata = self.bert_model(\n",
    "            metadata_ids, \n",
    "            attention_mask=metadata_mask, \n",
    "            token_type_ids=metadata_token_type_ids, \n",
    "            return_dict=False\n",
    "        )\n",
    "        \n",
    "        output = self.classifier(metadata)\n",
    "        \n",
    "        return output.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d392efb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d75087",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.classification import MulticlassF1Score\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281e29c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "lr = 2e-4\n",
    "n_epochs = 100\n",
    "\n",
    "model = Classifier()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e032ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(\n",
    "    project=\"ELEC877\",\n",
    "    entity=\"debadityashome\",\n",
    "    id=\"(Baseline) - Metadata only Classifier\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ace63a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86102444",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956e26c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for module in list(model.bert_model.modules()):\n",
    "    for param in module.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f133856",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57879c3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optim = torch.optim.AdamW([param for param in model.parameters() if param.requires_grad == True], lr)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_metric = MulticlassF1Score(num_classes=len(label_map.keys())).to(device)\n",
    "valid_metric = MulticlassF1Score(num_classes=len(label_map.keys())).to(device)\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    print(f\"\\n****************** Epoch - {i} *******************\\n\\n\")\n",
    "    model.train()\n",
    "    #wandb.log({\"epoch\": i})\n",
    "    pbar = tqdm(train_dataloader)\n",
    "    loss_ema = None\n",
    "\n",
    "    for _, metadata_features, labels in pbar:\n",
    "\n",
    "        optim.zero_grad()\n",
    "        \n",
    "        metadata_ids = metadata_features['ids'].to(device)\n",
    "        metadata_token_type_ids = metadata_features['token_type_ids'].to(device)\n",
    "        metadata_mask = metadata_features['mask'].to(device)\n",
    "\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        prediction = model(\n",
    "            metadata_ids,\n",
    "            metadata_mask,\n",
    "            metadata_token_type_ids\n",
    "        )\n",
    "        \n",
    "        loss = criterion(prediction, labels)\n",
    "\n",
    "        loss.mean().backward()\n",
    "\n",
    "        pbar.set_description(f\"loss: {loss.mean().item():.4f}\")\n",
    "        \n",
    "        train_metric.update(prediction, labels)\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm(model.parameters(), 1)\n",
    "        \n",
    "        optim.step()\n",
    "    \n",
    "    print(f\"\\nTotal train F1 score: {train_metric.compute()}\")\n",
    "    \n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        count = 0\n",
    "\n",
    "        print(\"\\n****Inference over Validation data****\\n\")\n",
    "\n",
    "        for _, metadata_features, labels in tqdm(valid_dataloader):\n",
    "\n",
    "            metadata_ids = metadata_features['ids'].to(device)\n",
    "            metadata_token_type_ids = metadata_features['token_type_ids'].to(device)\n",
    "            metadata_mask = metadata_features['mask'].to(device)\n",
    "\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            prediction = model(\n",
    "                metadata_ids,\n",
    "                metadata_mask,\n",
    "                metadata_token_type_ids\n",
    "            )\n",
    "\n",
    "            valid_metric.update(prediction, labels)\n",
    "\n",
    "        print(f\"\\nTotal valid F1 score: {valid_metric.compute()}\")\n",
    "        \n",
    "        wandb.log(\n",
    "        {\n",
    "            \"train F1-score\": train_metric.compute().item(),\n",
    "            \"validation F1-score\": valid_metric.compute().item(),\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    train_metric.reset()\n",
    "    valid_metric.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b8f416",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "test_metric = MulticlassF1Score(num_classes=len(label_map.keys())).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    count = 0\n",
    "\n",
    "    print(\"\\n****Inference over Test data****\\n\")\n",
    "\n",
    "    for _, metadata_features, labels in tqdm(valid_dataloader):\n",
    "\n",
    "        metadata_ids = metadata_features['ids'].to(device)\n",
    "        metadata_token_type_ids = metadata_features['token_type_ids'].to(device)\n",
    "        metadata_mask = metadata_features['mask'].to(device)\n",
    "\n",
    "        labels = labels.float().to(device)\n",
    "\n",
    "        prediction = model(\n",
    "            metadata_ids,\n",
    "            metadata_mask,\n",
    "            metadata_token_type_ids\n",
    "        )\n",
    "\n",
    "        test_metric.update(prediction, labels)\n",
    "        \n",
    "    print(f\"\\nTotal test F1 score: {test_metric.compute()}\")\n",
    "        \n",
    "    wandb.log(\n",
    "    {\n",
    "        \"test F1-score\": test_metric.compute().item(),\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5f652e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch-GPU",
   "language": "python",
   "name": "torch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
